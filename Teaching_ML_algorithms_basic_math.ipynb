{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "heard-manner",
   "metadata": {},
   "source": [
    "# Teaching ML algorithms how to add, divide, modulo, and use exponents.\n",
    "\n",
    "### Intro\n",
    "This work was inspired by blog post by Mario Filho where he was training XgBoost on data for the 4 basic mathematical operations of add, subtract, multiply, and divde. The blog post can be found here:\n",
    "https://www.mariofilho.com/can-gradient-boosting-learn-simple-arithmetic/\n",
    "\n",
    "I was interested by his initial findings and was curious to see how other machine learning algorithms would perform. How hard is it for advanced algorithms to learn other basic mathematical operations like modulo and exponents.\n",
    "\n",
    "### Approach\n",
    "\n",
    "1. Generate a dataset of 1,000 rows of number pairs ranging between zero and ten. Produce a target variable for each mathematical operation by applying it to each row of number pairs in the feature vector.\n",
    "2. Create a dictionary with various ML algorithm instantiations. This notebook currently tests the following algorithms:\n",
    "- Linear Regression\n",
    "- Ridge Regression\n",
    "- Ada Boost Regressor\n",
    "- Random Forest Regressor\n",
    "- Gaussian Process Regressor\n",
    "- XgBoost Regressor\n",
    "- Multi-layer Perceptron regressor\n",
    "\n",
    "3. Split the data with a train-test split of 33% test, 67% train.\n",
    "4. Loop over the operations and over the models. Train each model for an operation, predict the target variable on the test feature vector and then compare the prediction of the test target variable with the orginal value. Calculate the RMSE and the R2 score of the prediction.\n",
    "5. Identify the models that performed the best for each metric for each of the four mathematical operations.\n",
    "\n",
    "\n",
    "### Results\n",
    "Results for models built with a dataset containing 1,000 rows\n",
    "\n",
    "| Operation   | Metric   | Model                      |\n",
    "|:------------|:---------|:---------------------------|\n",
    "| Addition    | RMSE     | Linear Regression          |\n",
    "| Addition    | R2_score | Linear Regression          |\n",
    "| Division    | RMSE     | XgBoost Regressor          |\n",
    "| Division    | R2_score | XgBoost Regressor          |\n",
    "| Modulo      | RMSE     | Random Forest Regressor    |\n",
    "| Modulo      | R2_score | Random Forest Regressor    |\n",
    "| Power       | RMSE     | Gaussian Process Regressor |\n",
    "| Power       | R2_score | Gaussian Process Regressor |\n",
    "\n",
    "### Next steps:\n",
    "- Expand the feature vector space to include 0 and negative numbers.\n",
    "- Test more operations\n",
    "- Add more sklearn models (deep learning?)\n",
    "- Metric results as a function of dataset size (n = 10, 100, 1000, 1000) Make a log log plot of metrics vs. dataset size with different lines for each function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "similar-solomon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add, truediv, mod, pow\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import AdaBoostRegressor, RandomForestRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "breeding-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "private-rainbow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set numpy random seed\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-while",
   "metadata": {},
   "source": [
    "## Creating our feature vector and target variable\n",
    "\n",
    "Create a FV with 1,000 rows and two features. These two features are the numbers that will receive the mathematical operation.\n",
    "\n",
    "Then we create 4 different target variables based on the mathematical operation we are trying to reproduce via ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "alternate-offense",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X feature vector\n",
    "X = 10*np.random.rand(10000, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "controlling-strand",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create target variable for adding\n",
    "y_add = np.fromiter(map(add, [x[0] for x in X],[x[1] for x in X]), dtype=float)\n",
    "\n",
    "# check the creation of the target variable\n",
    "for idx, x in enumerate(X):\n",
    "    assert(x[0]+x[1]==y_add[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sweet-wrestling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create target variable for division\n",
    "y_div = np.fromiter(map(truediv, [x[0] for x in X],[x[1] for x in X]), dtype=float)\n",
    "\n",
    "# check the creation of the target variable\n",
    "for idx, x in enumerate(X):\n",
    "    assert(x[0]/x[1]==y_div[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "expanded-panic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create target variable for mod\n",
    "y_mod = np.fromiter(map(mod, [x[0] for x in X],[x[1] for x in X]), dtype=float)\n",
    "\n",
    "# check the creation of the target variable\n",
    "for idx, x in enumerate(X):\n",
    "    assert(x[0]%x[1]==y_mod[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "incomplete-bandwidth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create target variable for powers\n",
    "y_pow = np.fromiter(map(pow, [x[0] for x in X],[x[1] for x in X]), dtype=float)\n",
    "\n",
    "# check the creation of the target variable\n",
    "for idx, x in enumerate(X):\n",
    "    assert(x[0]**x[1]==y_pow[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-juvenile",
   "metadata": {},
   "source": [
    "# Operations and Model dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "coupled-company",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of the 4 types mathetical operations the algorithms will learn\n",
    "op_target_dict = {\"Addition\": y_add,\n",
    "                  \"Division\": y_div,\n",
    "                  \"Modulo\": y_mod,\n",
    "                  \"Power\": y_pow,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "working-synthetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\"Linear Regression\": LinearRegression(),\n",
    "              \"Ridge Regression\": Ridge(random_state=0),\n",
    "              \"Ada Boost Regressor\": AdaBoostRegressor(random_state=0),\n",
    "              \"Random Forest Regressor\": RandomForestRegressor(random_state=0),\n",
    "              \"Gaussian Process Regressor\": GaussianProcessRegressor(random_state=0),\n",
    "              \"XgBoost Regressor\": XGBRegressor(random_state=0),\n",
    "              \"Multi-layer Perceptron regressor\": MLPRegressor(max_iter=1000, learning_rate_init=0.01,\n",
    "                                                               learning_rate='adaptive', random_state=0)\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-yemen",
   "metadata": {},
   "source": [
    "# Training and Testing\n",
    " - Train-test split the data set with a test size of 33%.\n",
    " - Loop through every operation in the op_target_dict.\n",
    " - Loop through every model in the model_dict.\n",
    " - Train the model\n",
    " - Score the test feature vector\n",
    " - Calculated the RMSE and the r2 score for the test target variable.\n",
    " - Save results to a dataframe.\n",
    " \n",
    "Note: The StandardScalar was considered for use, since that is the best practice for certain algorithms such as the multi-layer percepton regressor. However, it was not considered, so as to no muddy the relationships between the input values and the output target from the mathematical operations. It was unclear if the standardscaler would decrease the effectiveness of other algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "radical-hartford",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model Linear Regression on operation Addition\n",
      "Training model Ridge Regression on operation Addition\n",
      "Training model Ada Boost Regressor on operation Addition\n",
      "Training model Random Forest Regressor on operation Addition\n",
      "Training model Gaussian Process Regressor on operation Addition\n",
      "Training model XgBoost Regressor on operation Addition\n",
      "Training model Multi-layer Perceptron regressor on operation Addition\n",
      "Training model Linear Regression on operation Division\n",
      "Training model Ridge Regression on operation Division\n",
      "Training model Ada Boost Regressor on operation Division\n",
      "Training model Random Forest Regressor on operation Division\n",
      "Training model Gaussian Process Regressor on operation Division\n",
      "Training model XgBoost Regressor on operation Division\n",
      "Training model Multi-layer Perceptron regressor on operation Division\n",
      "Training model Linear Regression on operation Modulo\n",
      "Training model Ridge Regression on operation Modulo\n",
      "Training model Ada Boost Regressor on operation Modulo\n",
      "Training model Random Forest Regressor on operation Modulo\n",
      "Training model Gaussian Process Regressor on operation Modulo\n",
      "Training model XgBoost Regressor on operation Modulo\n",
      "Training model Multi-layer Perceptron regressor on operation Modulo\n",
      "Training model Linear Regression on operation Power\n",
      "Training model Ridge Regression on operation Power\n",
      "Training model Ada Boost Regressor on operation Power\n",
      "Training model Random Forest Regressor on operation Power\n",
      "Training model Gaussian Process Regressor on operation Power\n",
      "Training model XgBoost Regressor on operation Power\n",
      "Training model Multi-layer Perceptron regressor on operation Power\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/u398323/miniconda3/envs/bryan-env/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "\n",
    "for operation, y_ in op_target_dict.items():\n",
    "    #Standard Scalar optional here\n",
    "    #X = StandardScaler().fit_transform(X)\n",
    "    X_train_, X_test_, y_train_, y_test_ = train_test_split(X, y_, test_size=0.33, random_state=42)\n",
    "    \n",
    "    for model_name, model in model_dict.items():\n",
    "        print(f\"Training model {model_name} on operation {operation}\")\n",
    "        model_fit = model.fit(X_train_, y_train_, )\n",
    "        train_score_ = model_fit.score(X_train_, y_train_)\n",
    "        y_pred_ = model_fit.predict(X_test_)\n",
    "        rmse_ = mean_squared_error(y_test_, y_pred_, squared=False)\n",
    "        r2_ = r2_score(y_test_, y_pred_)\n",
    "        outputs.append(pd.DataFrame(data={\"Operation\": [operation],\"Model\": [model_name],\n",
    "                                          \"train_score\": [train_score_], \"RMSE\": [rmse_],\n",
    "                                          \"R2_score\": [r2_],\n",
    "                                          \"abs_R2_score-1\": [abs(r2_-1)],}))\n",
    "df_results = pd.concat(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "matched-paraguay",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the best model for each operation by metric\n",
    "best_model_outputs = []\n",
    "\n",
    "for op_ in op_target_dict.keys():\n",
    "    \n",
    "    best_model_outputs.append(pd.DataFrame(data={\"Operation\": [op_],\n",
    "                                                 \"Metric\": ['RMSE'],\n",
    "                    \"Value\": [df_results[df_results.Operation==op_].sort_values('RMSE').RMSE.values[0]],\n",
    "                    \"Model\": [df_results[df_results.Operation==op_].sort_values('RMSE').Model.values[0]]\n",
    "                                                }))\n",
    "    best_model_outputs.append(pd.DataFrame(data={\"Operation\": [op_],\n",
    "                                             \"Metric\": ['R2_score'],\n",
    "        \"Value\": [df_results[df_results.Operation==op_].sort_values('abs_R2_score-1').R2_score.values[0]],\n",
    "                    \"Model\": [df_results[df_results.Operation==op_].sort_values('abs_R2_score-1').Model.values[0]],\n",
    "                                            }))\n",
    "\n",
    "df_best_models = pd.concat(best_model_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "smaller-somerset",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Operation</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Addition</td>\n",
       "      <td>RMSE</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Linear Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Addition</td>\n",
       "      <td>R2_score</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Linear Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Division</td>\n",
       "      <td>RMSE</td>\n",
       "      <td>144.426</td>\n",
       "      <td>XgBoost Regressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Division</td>\n",
       "      <td>R2_score</td>\n",
       "      <td>0.408</td>\n",
       "      <td>XgBoost Regressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Modulo</td>\n",
       "      <td>RMSE</td>\n",
       "      <td>0.496</td>\n",
       "      <td>Gaussian Process Regressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Modulo</td>\n",
       "      <td>R2_score</td>\n",
       "      <td>0.945</td>\n",
       "      <td>Gaussian Process Regressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Power</td>\n",
       "      <td>RMSE</td>\n",
       "      <td>23170.819</td>\n",
       "      <td>Gaussian Process Regressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Power</td>\n",
       "      <td>R2_score</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Gaussian Process Regressor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Operation    Metric     Value                       Model\n",
       "0  Addition      RMSE     0.000           Linear Regression\n",
       "0  Addition  R2_score     1.000           Linear Regression\n",
       "0  Division      RMSE   144.426           XgBoost Regressor\n",
       "0  Division  R2_score     0.408           XgBoost Regressor\n",
       "0    Modulo      RMSE     0.496  Gaussian Process Regressor\n",
       "0    Modulo  R2_score     0.945  Gaussian Process Regressor\n",
       "0     Power      RMSE 23170.819  Gaussian Process Regressor\n",
       "0     Power  R2_score     1.000  Gaussian Process Regressor"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show the best models for operations by metrics\n",
    "display(df_best_models.sort_values(['Operation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "structural-lawrence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Operation   | Metric   | Model                      |\n",
      "|:------------|:---------|:---------------------------|\n",
      "| Addition    | RMSE     | Linear Regression          |\n",
      "| Addition    | R2_score | Linear Regression          |\n",
      "| Division    | RMSE     | XgBoost Regressor          |\n",
      "| Division    | R2_score | XgBoost Regressor          |\n",
      "| Modulo      | RMSE     | Gaussian Process Regressor |\n",
      "| Modulo      | R2_score | Gaussian Process Regressor |\n",
      "| Power       | RMSE     | Gaussian Process Regressor |\n",
      "| Power       | R2_score | Gaussian Process Regressor |\n"
     ]
    }
   ],
   "source": [
    "# tabulate best model list for markdown format\n",
    "print(df_best_models[['Operation', 'Metric', 'Model']].to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caroline-oxygen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Operation</th>\n",
       "      <th>Model</th>\n",
       "      <th>train_score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2_score</th>\n",
       "      <th>abs_R2_score-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Addition</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Addition</td>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Addition</td>\n",
       "      <td>Ada Boost Regressor</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Addition</td>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.049</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Addition</td>\n",
       "      <td>Gaussian Process Regressor</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Addition</td>\n",
       "      <td>XgBoost Regressor</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Addition</td>\n",
       "      <td>Multi-layer Perceptron regressor</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.017</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Division</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.021</td>\n",
       "      <td>187.329</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Division</td>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>0.021</td>\n",
       "      <td>187.329</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Division</td>\n",
       "      <td>Ada Boost Regressor</td>\n",
       "      <td>0.932</td>\n",
       "      <td>154.592</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Division</td>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>0.977</td>\n",
       "      <td>149.886</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Division</td>\n",
       "      <td>Gaussian Process Regressor</td>\n",
       "      <td>0.815</td>\n",
       "      <td>180.575</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Division</td>\n",
       "      <td>XgBoost Regressor</td>\n",
       "      <td>1.000</td>\n",
       "      <td>144.426</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Division</td>\n",
       "      <td>Multi-layer Perceptron regressor</td>\n",
       "      <td>0.797</td>\n",
       "      <td>158.692</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Modulo</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.423</td>\n",
       "      <td>1.600</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Modulo</td>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>0.423</td>\n",
       "      <td>1.600</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Modulo</td>\n",
       "      <td>Ada Boost Regressor</td>\n",
       "      <td>0.652</td>\n",
       "      <td>1.276</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Modulo</td>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Modulo</td>\n",
       "      <td>Gaussian Process Regressor</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Modulo</td>\n",
       "      <td>XgBoost Regressor</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Modulo</td>\n",
       "      <td>Multi-layer Perceptron regressor</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Power</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.079</td>\n",
       "      <td>251948135.089</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Power</td>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>0.079</td>\n",
       "      <td>251948019.083</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Power</td>\n",
       "      <td>Ada Boost Regressor</td>\n",
       "      <td>0.957</td>\n",
       "      <td>79054284.105</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Power</td>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>0.997</td>\n",
       "      <td>30434215.384</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Power</td>\n",
       "      <td>Gaussian Process Regressor</td>\n",
       "      <td>1.000</td>\n",
       "      <td>23170.819</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Power</td>\n",
       "      <td>XgBoost Regressor</td>\n",
       "      <td>1.000</td>\n",
       "      <td>46558846.062</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Power</td>\n",
       "      <td>Multi-layer Perceptron regressor</td>\n",
       "      <td>0.025</td>\n",
       "      <td>257286304.841</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Operation                             Model  train_score          RMSE  \\\n",
       "0  Addition                 Linear Regression        1.000         0.000   \n",
       "0  Addition                  Ridge Regression        1.000         0.000   \n",
       "0  Addition               Ada Boost Regressor        0.964         0.795   \n",
       "0  Addition           Random Forest Regressor        1.000         0.049   \n",
       "0  Addition        Gaussian Process Regressor        1.000         0.000   \n",
       "0  Addition                 XgBoost Regressor        1.000         0.110   \n",
       "0  Addition  Multi-layer Perceptron regressor        1.000         0.017   \n",
       "0  Division                 Linear Regression        0.021       187.329   \n",
       "0  Division                  Ridge Regression        0.021       187.329   \n",
       "0  Division               Ada Boost Regressor        0.932       154.592   \n",
       "0  Division           Random Forest Regressor        0.977       149.886   \n",
       "0  Division        Gaussian Process Regressor        0.815       180.575   \n",
       "0  Division                 XgBoost Regressor        1.000       144.426   \n",
       "0  Division  Multi-layer Perceptron regressor        0.797       158.692   \n",
       "0    Modulo                 Linear Regression        0.423         1.600   \n",
       "0    Modulo                  Ridge Regression        0.423         1.600   \n",
       "0    Modulo               Ada Boost Regressor        0.652         1.276   \n",
       "0    Modulo           Random Forest Regressor        0.992         0.502   \n",
       "0    Modulo        Gaussian Process Regressor        0.954         0.496   \n",
       "0    Modulo                 XgBoost Regressor        0.984         0.604   \n",
       "0    Modulo  Multi-layer Perceptron regressor        0.916         0.625   \n",
       "0     Power                 Linear Regression        0.079 251948135.089   \n",
       "0     Power                  Ridge Regression        0.079 251948019.083   \n",
       "0     Power               Ada Boost Regressor        0.957  79054284.105   \n",
       "0     Power           Random Forest Regressor        0.997  30434215.384   \n",
       "0     Power        Gaussian Process Regressor        1.000     23170.819   \n",
       "0     Power                 XgBoost Regressor        1.000  46558846.062   \n",
       "0     Power  Multi-layer Perceptron regressor        0.025 257286304.841   \n",
       "\n",
       "   R2_score  abs_R2_score-1  \n",
       "0     1.000           0.000  \n",
       "0     1.000           0.000  \n",
       "0     0.962           0.038  \n",
       "0     1.000           0.000  \n",
       "0     1.000           0.000  \n",
       "0     0.999           0.001  \n",
       "0     1.000           0.000  \n",
       "0     0.004           0.996  \n",
       "0     0.004           0.996  \n",
       "0     0.322           0.678  \n",
       "0     0.362           0.638  \n",
       "0     0.074           0.926  \n",
       "0     0.408           0.592  \n",
       "0     0.285           0.715  \n",
       "0     0.423           0.577  \n",
       "0     0.423           0.577  \n",
       "0     0.633           0.367  \n",
       "0     0.943           0.057  \n",
       "0     0.945           0.055  \n",
       "0     0.918           0.082  \n",
       "0     0.912           0.088  \n",
       "0     0.069           0.931  \n",
       "0     0.069           0.931  \n",
       "0     0.908           0.092  \n",
       "0     0.986           0.014  \n",
       "0     1.000           0.000  \n",
       "0     0.968           0.032  \n",
       "0     0.029           0.971  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# final results for all operations and models\n",
    "display(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-rendering",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
